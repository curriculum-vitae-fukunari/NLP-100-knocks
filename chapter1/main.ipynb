{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Set\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 00. 文字列の逆順\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_00: str = \"stressed\"\n",
    "words_00_inverse: str = words_00[::-1]\n",
    "words_00_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_01: str = \"パタトクカシーー\"\n",
    "words_01_odd: str = \"\"\n",
    "\n",
    "for index, word in enumerate(words_01):\n",
    "    if index in [0, 2, 4, 6]:\n",
    "        words_01_odd += word\n",
    "\n",
    "words_01_odd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patrol_car: str = \"パトカー\"\n",
    "taxi: str = \"タクシー\"\n",
    "patatokukashi: str = \"\"\n",
    "\n",
    "for patrol_car_char, taxi_char in zip(patrol_car, taxi):\n",
    "    patatokukashi = patatokukashi + patrol_car_char + taxi_char\n",
    "\n",
    "patatokukashi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "\n",
    "\"Now I need a drink, alcoholic of course,   \n",
    "after the heavy lectures involving quantum mechanics.\"  \n",
    "\n",
    "という文を単語に分解し、各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_03: str = \"Now I need a drink, alcoholic of course, \" \\\n",
    "                \"after the heavy lectures involving quantum mechanics.\"\n",
    "words_03 = words_03.replace(\",\", \"\")\n",
    "words_03 = words_03.replace(\".\", \"\")\n",
    "\n",
    "words_list: List[str] = words_03.split()\n",
    "words_count_list: List[int] = []\n",
    "for word in words_list:\n",
    "    words_count_list.append(len(word))\n",
    "\n",
    "words_count_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine.   \n",
    "New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"   \n",
    " \n",
    "という文を単語に分解し、  \n",
    "1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字、  \n",
    "それ以外の単語は先頭に2文字を取り出し、  \n",
    "取り出した文字列から単語の位置（先頭から何番目の単語か）への  \n",
    "連想配列（辞書型もしくはマップ型）を作成せよ。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'H',\n",
       " 1: 'He',\n",
       " 2: 'Li',\n",
       " 3: 'Be',\n",
       " 4: 'B',\n",
       " 5: 'C',\n",
       " 6: 'N',\n",
       " 7: 'O',\n",
       " 8: 'F',\n",
       " 9: 'Ne',\n",
       " 10: 'Na',\n",
       " 11: 'Mi',\n",
       " 12: 'Al',\n",
       " 13: 'Si',\n",
       " 14: 'P',\n",
       " 15: 'S',\n",
       " 16: 'Cl',\n",
       " 17: 'Ar',\n",
       " 18: 'K',\n",
       " 19: 'Ca'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_04: str = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. \" \\\n",
    "                \"New Nations Might Also Sign Peace Security Clause. \" \\\n",
    "                \"Arthur King Can.\"\n",
    "words_04 = words_04.replace(\".\", \"\")\n",
    "words_04_list: List[str] = words_04.split()\n",
    "\n",
    "single_list: List[int] = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "single_list_minus1: List[int] = list(map(lambda x: x - 1, single_list))\n",
    "\n",
    "dictionary: Dict[int, str] = {}\n",
    "for index, word in enumerate(words_04_list):\n",
    "    if index in single_list_minus1:\n",
    "        dictionary[index] = word[:1]\n",
    "    else:\n",
    "        dictionary[index] = word[:2]\n",
    "        \n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．  \n",
    "この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I am', 'am an', 'an NLPer'],\n",
       " ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語n-gramを返す関数\n",
    "def words_n_gram(*, words: str, n: int) -> List[str]:\n",
    "    words_list: List[str] = words.split()\n",
    "    \n",
    "    # 単語数が指定したnの値未満の場合、空の配列を返却する\n",
    "    if len(words_list) < n:\n",
    "        return []\n",
    "    \n",
    "    words_n_gram_list: List[str] = []\n",
    "    for index in range(len(words_list) - n + 1):\n",
    "        words_n_gram_list.append(\" \".join(words_list[index: index + n]))\n",
    "        \n",
    "    return words_n_gram_list\n",
    "\n",
    "    \n",
    "# 文字n-gramを返す関数\n",
    "def chars_n_gram(*, words: str, n: int):\n",
    "    \n",
    "    # 文字数が指定したnの値未満の場合、空の配列を返却する\n",
    "    if len(words) < n:\n",
    "        return []\n",
    "    \n",
    "    chars_n_gram_list: List[str] = []\n",
    "    for index in range(len(words) - n + 1):\n",
    "        chars_n_gram_list.append(\"\".join(words[index: index + n]))\n",
    "    \n",
    "    return chars_n_gram_list\n",
    "\n",
    "\n",
    "# 単語n-gram、文字n-gramをタプルで返す関数   \n",
    "def n_gram(*, words: str, n: int) -> Tuple[List[str], List[str]]:\n",
    "    \n",
    "    return words_n_gram(words=words, n=n), chars_n_gram(words=words, n=n)\n",
    " \n",
    "\n",
    "words_05: str = \"I am an NLPer\"\n",
    "n_gram(words=words_05, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を、  \n",
    "それぞれXとYとして求め、XとYの和集合・積集合・差集合を求めよ。  \n",
    "さらに、'se'というbi-gramがXおよびYに含まれるかどうかを調べよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union:  {'ar', 'ra', 'pa', 'se', 'ap', 'ad', 'is', 'di', 'ph', 'gr', 'ag'}\n",
      "intersection:  {'ap', 'ar', 'ra', 'pa'}\n",
      "difference:  {'ad', 'is', 'di', 'se'}\n",
      "\"se\" is in x:  True\n",
      "\"se\" is in y:  False\n"
     ]
    }
   ],
   "source": [
    "paraparaparadise: str = \"paraparaparadise\"\n",
    "paragraph: str = \"paragraph\"\n",
    "\n",
    "x: Set[str] = set(n_gram(words=paraparaparadise, n=2)[1])\n",
    "y: Set[str] = set(n_gram(words=paragraph, n=2)[1])\n",
    " \n",
    "union: Set[str] = x | y \n",
    "intersection: Set[str] = x & y\n",
    "difference: Set[str] = x - y\n",
    "\n",
    "print(\"union: \", union)\n",
    "print(\"intersection: \", intersection)\n",
    "print(\"difference: \", difference)\n",
    "\n",
    "print(\"\\\"se\\\" is in x: \", \"se\" in x)\n",
    "print(\"\\\"se\\\" is in y: \", \"se\" in y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ。  \n",
    "さらに、x=12, y=\"気温\", z=22.4として、実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def template_07(*, x: int, y: str, z: float) -> str:\n",
    "    return str(x) + \"時の\" + str(y) + \"は\" + str(z)\n",
    "\n",
    "\n",
    "template_07(x=12, y=\"気温\", z=22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ。\n",
    "* 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "* その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い、英語のメッセージを暗号化・復号化せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encrypted:  Crksvi\n",
      "decoded:  Cipher\n"
     ]
    }
   ],
   "source": [
    "def cipher(*, words: str):\n",
    "    \n",
    "    encrypted_words: str = \"\"\n",
    "    for char in words:\n",
    "        if char.isalpha() and char.islower():\n",
    "            encrypted_words = encrypted_words + chr(219 - ord(char))\n",
    "        else:\n",
    "            encrypted_words = encrypted_words + char\n",
    "            \n",
    "    return encrypted_words\n",
    "\n",
    "\n",
    "encrypted: str = cipher(words=\"Cipher\")\n",
    "decoded: str = cipher(words=encrypted)\n",
    "\n",
    "print(\"encrypted: \", encrypted)\n",
    "print(\"decoded: \", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し、  \n",
    "それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ。  \n",
    "ただし，長さが４以下の単語は並び替えないこととする。  \n",
    "\n",
    "適当な英語の文\n",
    "\n",
    "\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "\n",
    "を与え、その実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I co'dulnt beivlee that I cuold aclluaty udatnersnd what I was rndeaig : the peameonhnl pewor of the human mind .\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_09: str = \"I couldn't believe that I could actually understand what I was reading : \" \\\n",
    "                \"the phenomenal power of the human mind .\"\n",
    "words_09_list: str = words_09.split()\n",
    "\n",
    "typoglycemia: str = \"\"\n",
    "for word in words_09_list:\n",
    "    if len(word) <= 4:\n",
    "        typoglycemia = typoglycemia + \" \" + word\n",
    "\n",
    "    else:\n",
    "        center_word_list: List[str] = []\n",
    "        for center_word_char in word[1:-1]:\n",
    "            center_word_list.append(center_word_char)\n",
    "\n",
    "        random.shuffle(center_word_list)\n",
    "\n",
    "        first: chr = word[0]\n",
    "        last: chr = word[-1]\n",
    "\n",
    "        word_more_than_4: str = first\n",
    "        for center_word_char in center_word_list:\n",
    "            word_more_than_4 = word_more_than_4 + center_word_char\n",
    "        word_more_than_4 += last\n",
    "\n",
    "        typoglycemia += \" \" + word_more_than_4\n",
    "\n",
    "typoglycemia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
