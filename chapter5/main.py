'''
å¤ç›®æ¼±çŸ³ã®å°èª¬ã€å¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€ã®æ–‡ç« ï¼ˆneko.txtï¼‰ã‚’CaboChaã‚’ä½¿ã£ã¦ä¿‚ã‚Šå—ã‘è§£æã—ï¼Œ
ãã®çµæœã‚’neko.txt.cabochaã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã›ã‚ˆï¼
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨ã„ã¦ï¼Œä»¥ä¸‹ã®å•ã«å¯¾å¿œã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè£…ã›ã‚ˆï¼
'''

'''
ä¿‚ã‚Šå—ã‘è§£æ
http://blog.aqutras.com/entry/2016/04/18/210000

æ–‡ç« ã‚’å½¢æ…‹ç´ ã«åˆ†ã‘ãŸå¾Œã€ä¿®é£¾é–¢ä¿‚ã®è§£æã‚’è¡Œã†ã“ã¨
èªã¨èªã®ç¹‹ãŒã‚Šã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
äººé–“ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„å½¢å¼ã§å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
'''

'''
Cabocha
http://chasen.naist.jp/chaki/t/2005-08-29/doc/CaboCha%20Yet%20Another%20Japanese%20Dependency%20Structure%20Analyzer.htm
SVMã«åŸºã¥ãé«˜æ€§èƒ½ãªä¿‚ã‚Šå—ã‘è§£æå™¨è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚
'''

'''
ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

CaboChaã‚’å‹•ã‹ã™ãŸã‚ã«ã¯ä»¥ä¸‹ã®3ã¤ãŒå¿…è¦ã¨ãªã‚‹ã€‚
* CRF++
* MeCab
* mecab-ipadicãªã©ã®è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«

CRF++

æ¡ä»¶ä»˜ãç¢ºç‡å ´ã¨ã„ã†ã‚‚ã®ã‚’ç”¨ã„ã¦ã„ã‚‹ã‚‰ã—ã„

brew install crf++
ğŸº  /usr/local/Cellar/crf++/0.58: 12 files, 719.5KB

brew install cabocha
ğŸº  /usr/local/Cellar/cabocha/0.69: 27 files, 236MB
'''

'''
CaboChaã§å§‹ã‚ã‚‹ä¿‚ã‚Šå—ã‘è§£æ
https://qiita.com/nezuq/items/f481f07fc0576b38e81d

cabocha -f1
ä¸€éƒã¯äºŒéƒã‚’æã„ãŸçµµã‚’ä¸‰éƒã«è´ˆã£ãŸã€‚

* 0 5D 0/1 -0.620584
ä¸€éƒ  åè©,äººå,*,*,ä¸€éƒ,ã„ã¡ã‚ã†,*
ã¯ åŠ©è©,å‰¯åŠ©è©,*,*,ã¯,ã¯,*
* 1 2D 0/1 1.710282
äºŒéƒ  åè©,äººå,*,*,äºŒéƒ,ã˜ã‚ã†,*
ã‚’ åŠ©è©,æ ¼åŠ©è©,*,*,ã‚’,ã‚’,*
* 2 3D 0/0 1.594028
æã„ãŸ   å‹•è©,*,å­éŸ³å‹•è©ã‚«è¡Œ,ã‚¿å½¢,æã,ãˆãŒã„ãŸ,ä»£è¡¨è¡¨è¨˜:æã
* 3 5D 0/1 -0.620584
çµµ åè©,æ™®é€šåè©,*,*,çµµ,ãˆ,æ¼¢å­—èª­ã¿:éŸ³ ä»£è¡¨è¡¨è¨˜:çµµ
ã‚’ åŠ©è©,æ ¼åŠ©è©,*,*,ã‚’,ã‚’,*
* 4 5D 0/1 -0.620584
ä¸‰éƒ  åè©,äººå,*,*,ä¸‰éƒ,ã•ã¶ã‚ã†,*
ã« åŠ©è©,æ ¼åŠ©è©,*,*,ã«,ã«,*
* 5 -1D 0/0 0.000000
è´ˆã£ãŸ   å‹•è©,*,å­éŸ³å‹•è©ãƒ©è¡Œ,ã‚¿å½¢,è´ˆã‚‹,ãŠãã£ãŸ,ä»£è¡¨è¡¨è¨˜:è´ˆã‚‹
ã€‚ ç‰¹æ®Š,å¥ç‚¹,*,*,ã€‚,ã€‚,*
EOS

1è¡Œç›®
1. *
2. æ–‡ç¯€ç•ªå·
3. ä¿‚ã‚Šå…ˆã®æ–‡ç¯€ç•ªå·(ä¿‚ã‚Šå…ˆãªã—:-1)
4. ä¸»è¾ã®å½¢æ…‹ç´ ç•ªå·/æ©Ÿèƒ½èªã®å½¢æ…‹ç´ ç•ªå·
5. ä¿‚ã‚Šé–¢ä¿‚ã®ã‚¹ã‚³ã‚¢(å¤§ãã„æ–¹ãŒä¿‚ã‚Šã‚„ã™ã„)

2è¡Œç›®
1. è¡¨å±¤å½¢ ï¼ˆTabåŒºåˆ‡ã‚Šï¼‰
2. å“è©
3. å“è©ç´°åˆ†é¡1
4. å“è©ç´°åˆ†é¡2
5. å“è©ç´°åˆ†é¡3
6. æ´»ç”¨å½¢
7. æ´»ç”¨å‹
8. åŸå½¢
9. èª­ã¿
10. ç™ºéŸ³
'''

'''
$ cabocha -f1 neko.txt -o neko.txt.cabocha
'''

'''
40. ä¿‚ã‚Šå—ã‘è§£æçµæœã®èª­ã¿è¾¼ã¿ï¼ˆå½¢æ…‹ç´ ï¼‰
å½¢æ…‹ç´ ã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹Morphã‚’å®Ÿè£…ã›ã‚ˆï¼
ã“ã®ã‚¯ãƒ©ã‚¹ã¯è¡¨å±¤å½¢ï¼ˆsurfaceï¼‰ï¼ŒåŸºæœ¬å½¢ï¼ˆbaseï¼‰ï¼Œå“è©ï¼ˆposï¼‰ï¼Œå“è©ç´°åˆ†é¡1ï¼ˆpos1ï¼‰ã‚’ãƒ¡ãƒ³ãƒå¤‰æ•°ã«æŒã¤ã“ã¨ã¨ã™ã‚‹ï¼
ã•ã‚‰ã«ï¼ŒCaboChaã®è§£æçµæœï¼ˆneko.txt.cabochaï¼‰ã‚’èª­ã¿è¾¼ã¿ï¼Œå„æ–‡ã‚’Morphã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¡¨ç¾ã—ï¼Œ
3æ–‡ç›®ã®å½¢æ…‹ç´ åˆ—ã‚’è¡¨ç¤ºã›ã‚ˆï¼
'''
from typing import List, Tuple
from chapter5.util import Chunk, Morph, ReceivedRelative
import re


def received_relative(item_list: List[str]) -> ReceivedRelative:

    return ReceivedRelative(chunk_number=int(item_list[1]),
                            chunk_number_modifiee=int(item_list[2].strip("D")),
                            morph_number_head=int(item_list[3].split("/")[0]),
                            morph_number_function_word=int(item_list[3].split("/")[1]),
                            score_relation=float(item_list[4]))


def morph(item_list: List[str]) -> Morph:

    # "*"ã§è£œå®Œ
    while len(split_line) < 10:
        split_line.append("*")

    return Morph(surface=item_list[0],
                 pos=item_list[1],
                 pos1=item_list[2],
                 pos2=item_list[3],
                 pos3=item_list[4],
                 inflection=item_list[5],
                 conjugation=item_list[6],
                 base=item_list[7],
                 syllabary=item_list[8],
                 pronunciation=item_list[9])


with open("./chapter5/neko.txt.cabocha", "r") as file:
    lines: List[str] = file.readlines()

sequences: List[List[str]] = []
sequence: List[str] = []
for line in lines:
    # æ–‡ã®çµ‚ã‚ã‚Šã‚’è¡¨ã™EOSãŒå…¥ã£ã¦ã„ã‚‹å ´åˆ
    if line == "EOS\n":
        sequences.append(sequence)
        sequence = []
    # ä¿‚ã‚Šå—ã‘ã‹ã€å½¢æ…‹ç´ ã‚’è¡¨ã—ã¦ã„ã‚‹å ´åˆ
    else:
        sequence.append(line)

sentences: List[List[Chunk]] = []
sentence: List[Chunk] = []
for sequence in sequences:
    if len(sequence) == 0:
        continue

    morph_list: List[Morph] = []
    for index, line in enumerate(sequence):
        split_line: List[str] = re.split("[\t, ]", line.strip("\n"))

        # å½¢æ…‹ç´ ã‚’è¡¨ã™è¡Œã®å ´åˆ
        if split_line[0] != "*":
            morph_: Morph = morph(item_list=split_line)
            morph_list.append(morph_)
            continue

        # ä¿‚ã‚Šã†ã‘ã‚’è¡¨ã™è¡Œã®å ´åˆ(æ–‡ã®å§‹ã¾ã‚Šã§ã¯ãªãã€ã™ã§ã«å½¢æ…‹ç´ ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹æ™‚)
        if index != 0:
            # ãã‚Œã¾ã§ã«å‡ºç¾ã—ãŸä¿‚ã‚Šå—ã‘ã¨å½¢æ…‹ç´ ã®ãƒªã‚¹ãƒˆã‹ã‚‰æ–‡ç¯€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã¤ãã‚Šã€æ–‡ãƒªã‚¹ãƒˆã«è¿½åŠ 
            chunk = Chunk(received_relative=received_relative_, morph_list=morph_list)
            sentence.append(chunk)
            morph_list = []

        received_relative_: ReceivedRelative = received_relative(item_list=split_line)

    chunk = Chunk(received_relative=received_relative_, morph_list=morph_list)
    sentence.append(chunk)
    sentences.append(sentence)
    morph_list = []
    sentence = []


# 8æ–‡ç›®ã®ä¸­èº«ã‚’ç¢ºèª
for chunk in sentences[8]:
    print(str(chunk))

'''
42. ä¿‚ã‚Šå…ƒã¨ä¿‚ã‚Šå…ˆã®æ–‡ç¯€ã®è¡¨ç¤º
ä¿‚ã‚Šå…ƒã®æ–‡ç¯€ã¨ä¿‚ã‚Šå…ˆã®æ–‡ç¯€ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¿ãƒ–åŒºåˆ‡ã‚Šå½¢å¼ã§ã™ã¹ã¦æŠ½å‡ºã›ã‚ˆï¼
ãŸã ã—ï¼Œå¥èª­ç‚¹ãªã©ã®è¨˜å·ã¯å‡ºåŠ›ã—ãªã„ã‚ˆã†ã«ã›ã‚ˆï¼
'''
for sentence in sentences:
    print()
    for index, chunk in enumerate(sentence):
        if index == len(sentence) - 1:
            break
        modifier: str = chunk.surface_words_except_syntax()
        modifiee: str = sentence[chunk.received_relative.chunk_number_modifiee].surface_words_except_syntax()
        print(modifier + "\t" + modifiee)

'''
43. åè©ã‚’å«ã‚€æ–‡ç¯€ãŒå‹•è©ã‚’å«ã‚€æ–‡ç¯€ã«ä¿‚ã‚‹ã‚‚ã®ã‚’æŠ½å‡º
åè©ã‚’å«ã‚€æ–‡ç¯€ãŒï¼Œå‹•è©ã‚’å«ã‚€æ–‡ç¯€ã«ä¿‚ã‚‹ã¨ãï¼Œã“ã‚Œã‚‰ã‚’ã‚¿ãƒ–åŒºåˆ‡ã‚Šå½¢å¼ã§æŠ½å‡ºã›ã‚ˆï¼
ãŸã ã—ï¼Œå¥èª­ç‚¹ãªã©ã®è¨˜å·ã¯å‡ºåŠ›ã—ãªã„ã‚ˆã†ã«ã›ã‚ˆï¼
'''
for sentence in sentences:
    print()
    for index, chunk in enumerate(sentence):
        if index == len(sentence) - 1:
            break
        if not chunk.is_contain_noun():
            continue
        modifier: str = chunk.surface_words_except_syntax()
        if not sentence[chunk.received_relative.chunk_number_modifiee].is_contain_verb():
            continue
        modifiee: str = sentence[chunk.received_relative.chunk_number_modifiee].surface_words_except_syntax()
        print(modifier + "\t" + modifiee)

'''
44. ä¿‚ã‚Šå—ã‘æœ¨ã®å¯è¦–åŒ–
ä¸ãˆã‚‰ã‚ŒãŸæ–‡ã®ä¿‚ã‚Šå—ã‘æœ¨ã‚’æœ‰å‘ã‚°ãƒ©ãƒ•ã¨ã—ã¦å¯è¦–åŒ–ã›ã‚ˆï¼å¯è¦–åŒ–ã«ã¯ï¼Œä¿‚ã‚Šå—ã‘æœ¨ã‚’DOTè¨€èªã«å¤‰æ›ã—ï¼ŒGraphvizã‚’ç”¨ã„ã‚‹ã¨ã‚ˆã„ï¼
ã¾ãŸï¼ŒPythonã‹ã‚‰æœ‰å‘ã‚°ãƒ©ãƒ•ã‚’ç›´æ¥çš„ã«å¯è¦–åŒ–ã™ã‚‹ã«ã¯ï¼Œpydotã‚’ä½¿ã†ã¨ã‚ˆã„ï¼
'''

'''
graphvizã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦
 brew install graphviz
'''
from pydotplus import Dot, Node, Edge

dot: Dot = Dot(graph_type="digraph")
node_list: List[Tuple[Node, int]] = []
for index, chunk in enumerate(sentences[5]):
    word: str = chunk.surface_words_except_syntax()
    chunk_number_modifiee: int = chunk.received_relative.chunk_number_modifiee
    node: Node = Node(word)
    dot.add_node(node)
    node_list.append((node, chunk_number_modifiee))

for index, node in enumerate(node_list):
    if index == len(node_list) - 1:
        continue
    node_modifier: Node = node[0]
    node_modifee: Node = node_list[node[1]][0]
    dot.add_edge(Edge(node_modifier, node_modifee))

dot.write(path="test.dot.jpg", format="jpg")


'''
45. å‹•è©ã®æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠ½å‡º
ä»Šå›ç”¨ã„ã¦ã„ã‚‹æ–‡ç« ã‚’ã‚³ãƒ¼ãƒ‘ã‚¹ã¨è¦‹ãªã—ï¼Œæ—¥æœ¬èªã®è¿°èªãŒå–ã‚Šã†ã‚‹æ ¼ã‚’èª¿æŸ»ã—ãŸã„ï¼ 
å‹•è©ã‚’è¿°èªï¼Œå‹•è©ã«ä¿‚ã£ã¦ã„ã‚‹æ–‡ç¯€ã®åŠ©è©ã‚’æ ¼ã¨è€ƒãˆï¼Œè¿°èªã¨æ ¼ã‚’ã‚¿ãƒ–åŒºåˆ‡ã‚Šå½¢å¼ã§å‡ºåŠ›ã›ã‚ˆï¼ 
ãŸã ã—ï¼Œå‡ºåŠ›ã¯ä»¥ä¸‹ã®ä»•æ§˜ã‚’æº€ãŸã™ã‚ˆã†ã«ã›ã‚ˆï¼

å‹•è©ã‚’å«ã‚€æ–‡ç¯€ã«ãŠã„ã¦ï¼Œæœ€å·¦ã®å‹•è©ã®åŸºæœ¬å½¢ã‚’è¿°èªã¨ã™ã‚‹
è¿°èªã«ä¿‚ã‚‹åŠ©è©ã‚’æ ¼ã¨ã™ã‚‹
è¿°èªã«ä¿‚ã‚‹åŠ©è©ï¼ˆæ–‡ç¯€ï¼‰ãŒè¤‡æ•°ã‚ã‚‹ã¨ãã¯ï¼Œã™ã¹ã¦ã®åŠ©è©ã‚’ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§è¾æ›¸é †ã«ä¸¦ã¹ã‚‹

ã€Œå¾è¼©ã¯ã“ã“ã§å§‹ã‚ã¦äººé–“ã¨ã„ã†ã‚‚ã®ã‚’è¦‹ãŸã€ã¨ã„ã†ä¾‹æ–‡ï¼ˆneko.txt.cabochaã®8æ–‡ç›®ï¼‰ã‚’è€ƒãˆã‚‹ï¼ 
ã“ã®æ–‡ã¯ã€Œå§‹ã‚ã‚‹ã€ã¨ã€Œè¦‹ã‚‹ã€ã®ï¼’ã¤ã®å‹•è©ã‚’å«ã¿ï¼Œ
ã€Œå§‹ã‚ã‚‹ã€ã«ä¿‚ã‚‹æ–‡ç¯€ã¯ã€Œã“ã“ã§ã€ï¼Œ
ã€Œè¦‹ã‚‹ã€ã«ä¿‚ã‚‹æ–‡ç¯€ã¯ã€Œå¾è¼©ã¯ã€ã¨ã€Œã‚‚ã®ã‚’ã€ã¨è§£æã•ã‚ŒãŸå ´åˆã¯ï¼Œ
æ¬¡ã®ã‚ˆã†ãªå‡ºåŠ›ã«ãªã‚‹ã¯ãšã§ã‚ã‚‹ï¼

å§‹ã‚ã‚‹  ã§
è¦‹ã‚‹    ã¯ ã‚’

ã‚³ãƒ¼ãƒ‘ã‚¹ä¸­ã§é »å‡ºã™ã‚‹è¿°èªã¨æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ„ã¿åˆã‚ã›
ã€Œã™ã‚‹ã€ã€Œè¦‹ã‚‹ã€ã€Œä¸ãˆã‚‹ã€ã¨ã„ã†å‹•è©ã®æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚³ãƒ¼ãƒ‘ã‚¹ä¸­ã§å‡ºç¾é »åº¦ã®é«˜ã„é †ã«ä¸¦ã¹ã‚ˆï¼‰
'''

lines: List[str] = []
for sentence in sentences:
    # å‹•è©ã‚’å«ã‚€æ–‡ç¯€ä¸­ã®å‹•è©ã®åŸºæœ¬å½¢, æ–‡ç¯€ã®ç•ªå·ã‚’æ¤œå‡ºã™ã‚‹
    verb_and_chunk_number: List[Tuple[str, int]] = []
    for index, chunk in enumerate(sentence):
        if chunk.is_contain_verb():
            for morph in chunk.morph_list:
                if morph.pos == "å‹•è©":
                    verb_and_chunk_number.append((morph.base, index))

    # åŠ©è©ã‚’å«ã‚€æ–‡ç¯€ä¸­ã®åŠ©è©ã®åŸºæœ¬å½¢ã€ä¿‚ã‚Šå…ˆã®æ–‡ç¯€ç•ªå·ã‚’æ¤œå‡ºã™ã‚‹
    particle_and_modifee_number: List[Tuple[str, int]] = []
    for index, chunk in enumerate(sentence):
        if chunk.is_contain_particle():
            modifiee_number: int = chunk.received_relative.chunk_number_modifiee
            for morph in chunk.morph_list:
                if morph.pos == "åŠ©è©":
                    particle_and_modifee_number.append((morph.base, modifiee_number))

    for verb, chunk_number in verb_and_chunk_number:
        line: str = verb + "\t"
        flag: bool = False  # è«¦ã‚ãŸ
        for particle, modifiee_number in particle_and_modifee_number:
            if chunk_number == modifiee_number:
                flag = True
                line += " " + particle
        if flag:
            lines.append(line)
            print(line)






